{
    "encoder": {
        "d_model": 512,
        "n_head": 8,
        "n_layers": 3,
        "drop_prob": 0.1,
        "ffn_hidden": 2048,
        "voc_size": 100001
    },
    "hparams": {
        "max_len": 130,
        "batch_size": 1000,
        "train_num_workers": 4,
        "val_num_workers": 3,
        "drop_last": false,
        "lr": 1e-4,
        "factor": 0.9,
        "adam_eps": 5e-9,
        "patience": 1,
        "min_lr": 1e-5,
        "max_epoch": 50,
        "clip": 50,
        "seed": 57,
        "weight_decay": 5e-4,
        "log_every_n_steps": 2000,
        "num_devices": 1,
        "val_check_interval": 1.0, 
        "accumulate_grad_batches": 32,
        "num_sanity_val_steps": 0,
        "precision": 32,
        "save_top_k": 1,
        "save_last": false,
        "save_every_n_train_steps": 0,
        "save_every_n_train_epochs": 1,
        "verbose": true,
        "instances_buffer_size": 24000,
        "buffer_max_batch": 3,
        "train_check_result_ratio": 0.1,
        "val_check_result_ratio": 0.1,
        "debug": false
    },
    "spectrum": {
        "max_mz": 1000,
        "min_mz": 50,
        "min_num_peaks": 5,
        "max_num_peaks": 500,
        "loss_mz_from": 1.0,
        "loss_mz_to": 1000.0,
        "resolution": 2,
        "tokenized": true,
        "use_neutral_loss": true,
        "neg": true
    },
    "path": {
        "model_dir": "./DeePFAS/deepfas_saved",
        "save_model_path": "./DeePFAS/deepfas_saved/deepfas_r2_best_model.pt",
        "train_data_path": "../DATASET/half_150_train.mgf",
        "val_data_path": "../DATASET/half_150_test.mgf"
    },
    "logger": {
        "project_name": "DeePFAS_AttentionConv2D",
        "wandb_entity_name": "wanghengzzz"
    }
}
